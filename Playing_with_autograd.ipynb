{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOkfvT3AIolC6somFuAzONk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adityav1810/ExploringPytorch/blob/main/Playing_with_autograd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFKlt4WkO7ug",
        "outputId": "87c54334-f2bb-4ac6-90d2-ea2a3f88c7cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([5.],requires_grad = True)\n",
        "w = torch.tensor([2.],requires_grad=True)"
      ],
      "metadata": {
        "id": "Yf_Aswa5PXRF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "x = 5\n",
        "w = 2\n",
        "\n",
        "y = wx^2\n",
        "dy/dx = 2 wx => ( 2.2.5 )=> 20\n",
        "dy / dw = x^2 => (5^2) => 25\n",
        "'''\n",
        "def f(w,x):\n",
        "  return w * (x**2)\n",
        "y = f(w,x)\n",
        "y.backward()\n"
      ],
      "metadata": {
        "id": "UFseoa6RPR-_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Computes dy/dw ie\n",
        "'''\n",
        "print(\"Gradient of Y w.rt. W \",w.grad)"
      ],
      "metadata": {
        "id": "NssXXg5ZSDJV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2d014e9-c5e8-4fd0-bda2-74383ffb2013"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient of Y w.rt. W  tensor([25.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Computes dy/dx ie\n",
        "'''\n",
        "print(\"Gradient of Y w.rt. X \",x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIMEQymQt_3R",
        "outputId": "456231a6-eecd-469d-ecf3-9b55e32bc1c5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient of Y w.rt. X  tensor([20.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def neuron(w,x,b):\n",
        "  return torch.add(torch.matmul(w,x),b)\n",
        "w = torch.tensor([3.,4.,3.],requires_grad = True)\n",
        "x = torch.tensor([7.,1.,2.],requires_grad = True)\n",
        "b = torch.tensor([1.,1.,1.],requires_grad = True)\n",
        "n = neuron(w,x,b)\n"
      ],
      "metadata": {
        "id": "iwt1hS5QuafF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n.sum().backward()"
      ],
      "metadata": {
        "id": "0g2B0zDOw21E"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w.grad,x.grad,b.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPoF1EbVxbpY",
        "outputId": "ae817fac-4f16-4897-97e8-0f5914c31e96"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([21.,  3.,  6.]), tensor([ 9., 12.,  9.]), tensor([1., 1., 1.]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXjaj_5B0ArG",
        "outputId": "3110d4b8-32dc-4594-8de8-45812842575d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([32., 32., 32.], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "inp = torch.eye(4, 5, requires_grad=True)\n",
        "out = (inp+1).pow(2).t()\n",
        "out.backward(torch.ones_like(out), retain_graph=True)\n",
        "print(f\"First call\\n{inp.grad}\")\n",
        "out.backward(torch.ones_like(out), retain_graph=True)\n",
        "print(f\"\\nSecond call\\n{inp.grad}\")\n",
        "inp.grad.zero_()\n",
        "out.backward(torch.ones_like(out), retain_graph=True)\n",
        "print(f\"\\nCall after zeroing gradients\\n{inp.grad}\")"
      ],
      "metadata": {
        "id": "W5ZVrHo-0CYs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9d24e6b-0591-46b9-ab76-373d664a686f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First call\n",
            "tensor([[4., 2., 2., 2., 2.],\n",
            "        [2., 4., 2., 2., 2.],\n",
            "        [2., 2., 4., 2., 2.],\n",
            "        [2., 2., 2., 4., 2.]])\n",
            "\n",
            "Second call\n",
            "tensor([[8., 4., 4., 4., 4.],\n",
            "        [4., 8., 4., 4., 4.],\n",
            "        [4., 4., 8., 4., 4.],\n",
            "        [4., 4., 4., 8., 4.]])\n",
            "\n",
            "Call after zeroing gradients\n",
            "tensor([[4., 2., 2., 2., 2.],\n",
            "        [2., 4., 2., 2., 2.],\n",
            "        [2., 2., 4., 2., 2.],\n",
            "        [2., 2., 2., 4., 2.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def exp_adder(x, y):\n",
        "    return 2 * x.exp() + 3 * y\n",
        "inputs = (w,x)\n",
        "torch.autograd.functional.jacobian(exp_adder, inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POkNSH_O1PXx",
        "outputId": "774c9ff5-38bc-47d8-a67d-9a02135d1326"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 40.1711,   0.0000,   0.0000],\n",
              "         [  0.0000, 109.1963,   0.0000],\n",
              "         [  0.0000,   0.0000,  40.1711]]),\n",
              " tensor([[3., 0., 0.],\n",
              "         [0., 3., 0.],\n",
              "         [0., 0., 3.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S0rSSSy71bZU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}